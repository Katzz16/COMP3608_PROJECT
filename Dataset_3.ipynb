{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "400aa714",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8fb5dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the relevant libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e32a0d",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff4546c",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "605b59b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4303 entries, 0 to 4302\n",
      "Data columns (total 18 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Age             4303 non-null   int64  \n",
      " 1   Gender          4303 non-null   int64  \n",
      " 2   BMI             4303 non-null   float64\n",
      " 3   SBP             4303 non-null   int64  \n",
      " 4   DBP             4303 non-null   int64  \n",
      " 5   FPG             4303 non-null   float64\n",
      " 6   Chol            4303 non-null   float64\n",
      " 7   Tri             4303 non-null   float64\n",
      " 8   HDL             4303 non-null   float64\n",
      " 9   LDL             4303 non-null   float64\n",
      " 10  ALT             4303 non-null   float64\n",
      " 11  BUN             4303 non-null   float64\n",
      " 12  CCR             4303 non-null   float64\n",
      " 13  FFPG            4303 non-null   float64\n",
      " 14  smoking         4303 non-null   float64\n",
      " 15  drinking        4303 non-null   float64\n",
      " 16  family_histroy  4303 non-null   int64  \n",
      " 17  Diabetes        4303 non-null   int64  \n",
      "dtypes: float64(12), int64(6)\n",
      "memory usage: 605.2 KB\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "df = pd.read_csv('diabetes.csv', encoding='latin1')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65382840",
   "metadata": {},
   "source": [
    "### Validation Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77be023a",
   "metadata": {},
   "source": [
    "The smoking column can take on 1 of 3 values depending on smoker status  \n",
    "* 1 - current  \n",
    "* 2 - former  \n",
    "* 3 - never  \n",
    "  \n",
    "  \n",
    "The drinking column can take on 1 of 3 values depending on drinker status  \n",
    "* 1 - current  \n",
    "* 2 - former  \n",
    "* 3 - never  \n",
    "  \n",
    "  \n",
    "The family_history column can take on 1 of 2 values  \n",
    "* 0 - no family history of diabetes  \n",
    "* 1 - family history of diabetes \n",
    "  \n",
    "  \n",
    "The Diabetes column can take on 1 of 2 values  \n",
    "* 0 - no diabetes  \n",
    "* 1 - diabetes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af826fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "1    2790\n",
      "2    1513\n",
      "Name: count, dtype: int64\n",
      "\n",
      " smoking\n",
      "3.000000    2534\n",
      "4.860753     888\n",
      "1.000000     745\n",
      "2.000000     136\n",
      "Name: count, dtype: int64\n",
      "\n",
      " drinking\n",
      "3.000000    2749\n",
      "4.860753     888\n",
      "2.000000     583\n",
      "1.000000      83\n",
      "Name: count, dtype: int64\n",
      "\n",
      " family_histroy\n",
      "0    4038\n",
      "1     265\n",
      "Name: count, dtype: int64\n",
      "\n",
      " Diabetes\n",
      "0    3000\n",
      "1    1303\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Getting the value counts for columns that can only contain certain values\n",
    "print(df['Gender'].value_counts())\n",
    "print(\"\\n\", df['smoking'].value_counts())\n",
    "print(\"\\n\", df['drinking'].value_counts())\n",
    "print(\"\\n\", df['family_histroy'].value_counts())\n",
    "print(\"\\n\", df['Diabetes'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f9a306",
   "metadata": {},
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acbedec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BMI</th>\n",
       "      <th>SBP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>FPG</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Tri</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>ALT</th>\n",
       "      <th>BUN</th>\n",
       "      <th>CCR</th>\n",
       "      <th>FFPG</th>\n",
       "      <th>smoking</th>\n",
       "      <th>drinking</th>\n",
       "      <th>family_histroy</th>\n",
       "      <th>Diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>20.7</td>\n",
       "      <td>112</td>\n",
       "      <td>64</td>\n",
       "      <td>5.52</td>\n",
       "      <td>4.79</td>\n",
       "      <td>1.67</td>\n",
       "      <td>4.860753</td>\n",
       "      <td>4.860753</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.91</td>\n",
       "      <td>61.0</td>\n",
       "      <td>10.30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>21.8</td>\n",
       "      <td>116</td>\n",
       "      <td>83</td>\n",
       "      <td>5.03</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>2.830000</td>\n",
       "      <td>14.5</td>\n",
       "      <td>4.68</td>\n",
       "      <td>63.1</td>\n",
       "      <td>5.10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>28.5</td>\n",
       "      <td>135</td>\n",
       "      <td>78</td>\n",
       "      <td>5.94</td>\n",
       "      <td>6.45</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1.290000</td>\n",
       "      <td>3.990000</td>\n",
       "      <td>44.5</td>\n",
       "      <td>5.74</td>\n",
       "      <td>57.4</td>\n",
       "      <td>6.70</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>26.9</td>\n",
       "      <td>127</td>\n",
       "      <td>63</td>\n",
       "      <td>4.99</td>\n",
       "      <td>4.34</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>2.480000</td>\n",
       "      <td>41.7</td>\n",
       "      <td>4.60</td>\n",
       "      <td>70.7</td>\n",
       "      <td>5.59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>25.8</td>\n",
       "      <td>144</td>\n",
       "      <td>83</td>\n",
       "      <td>5.47</td>\n",
       "      <td>4.27</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.840000</td>\n",
       "      <td>2.330000</td>\n",
       "      <td>13.9</td>\n",
       "      <td>4.32</td>\n",
       "      <td>50.1</td>\n",
       "      <td>5.12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3410</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>25.2</td>\n",
       "      <td>123</td>\n",
       "      <td>71</td>\n",
       "      <td>5.20</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.180000</td>\n",
       "      <td>2.530000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.90</td>\n",
       "      <td>78.9</td>\n",
       "      <td>5.40</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3411</th>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>20.7</td>\n",
       "      <td>121</td>\n",
       "      <td>74</td>\n",
       "      <td>6.16</td>\n",
       "      <td>5.51</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.860753</td>\n",
       "      <td>4.860753</td>\n",
       "      <td>12.7</td>\n",
       "      <td>5.48</td>\n",
       "      <td>55.4</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3412</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>23.8</td>\n",
       "      <td>102</td>\n",
       "      <td>69</td>\n",
       "      <td>4.20</td>\n",
       "      <td>7.51</td>\n",
       "      <td>2.54</td>\n",
       "      <td>2.060000</td>\n",
       "      <td>4.160000</td>\n",
       "      <td>17.2</td>\n",
       "      <td>4.30</td>\n",
       "      <td>54.7</td>\n",
       "      <td>4.60</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3413</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>20.9</td>\n",
       "      <td>121</td>\n",
       "      <td>75</td>\n",
       "      <td>4.08</td>\n",
       "      <td>3.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.430000</td>\n",
       "      <td>2.010000</td>\n",
       "      <td>18.7</td>\n",
       "      <td>4.65</td>\n",
       "      <td>66.6</td>\n",
       "      <td>4.92</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3414</th>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>19.9</td>\n",
       "      <td>129</td>\n",
       "      <td>80</td>\n",
       "      <td>4.71</td>\n",
       "      <td>5.29</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3.60</td>\n",
       "      <td>55.6</td>\n",
       "      <td>4.70</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3415 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Gender   BMI  SBP  DBP   FPG  Chol   Tri       HDL       LDL   ALT  \\\n",
       "0      32       1  20.7  112   64  5.52  4.79  1.67  4.860753  4.860753  64.0   \n",
       "1      47       1  21.8  116   83  5.03  4.32  1.19  1.200000  2.830000  14.5   \n",
       "2      56       2  28.5  135   78  5.94  6.45  2.69  1.290000  3.990000  44.5   \n",
       "3      30       1  26.9  127   63  4.99  4.34  1.28  1.350000  2.480000  41.7   \n",
       "4      32       2  25.8  144   83  5.47  4.27  0.43  1.840000  2.330000  13.9   \n",
       "...   ...     ...   ...  ...  ...   ...   ...   ...       ...       ...   ...   \n",
       "3410   32       1  25.2  123   71  5.20  4.38  1.12  1.180000  2.530000  19.0   \n",
       "3411   60       2  20.7  121   74  6.16  5.51  1.00  4.860753  4.860753  12.7   \n",
       "3412   33       2  23.8  102   69  4.20  7.51  2.54  2.060000  4.160000  17.2   \n",
       "3413   31       1  20.9  121   75  4.08  3.59  0.58  1.430000  2.010000  18.7   \n",
       "3414   44       2  19.9  129   80  4.71  5.29  0.62  1.660000  3.200000  12.6   \n",
       "\n",
       "       BUN   CCR   FFPG  smoking  drinking  family_histroy  Diabetes  \n",
       "0     4.91  61.0  10.30      3.0       3.0               0         1  \n",
       "1     4.68  63.1   5.10      3.0       3.0               0         0  \n",
       "2     5.74  57.4   6.70      3.0       3.0               0         0  \n",
       "3     4.60  70.7   5.59      1.0       3.0               0         0  \n",
       "4     4.32  50.1   5.12      3.0       3.0               0         0  \n",
       "...    ...   ...    ...      ...       ...             ...       ...  \n",
       "3410  2.90  78.9   5.40      3.0       3.0               0         0  \n",
       "3411  5.48  55.4   7.00      3.0       3.0               0         1  \n",
       "3412  4.30  54.7   4.60      3.0       3.0               0         0  \n",
       "3413  4.65  66.6   4.92      2.0       3.0               0         0  \n",
       "3414  3.60  55.6   4.70      3.0       3.0               0         0  \n",
       "\n",
       "[3415 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing rows with invalid values\n",
    "invalid = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if df.iloc[i]['smoking'] != 1 and df.iloc[i]['smoking'] != 2 and df.iloc[i]['smoking'] != 3 and df.iloc[i]['drinking'] != 1 and df.iloc[i]['drinking'] != 2 and df.iloc[i]['drinking'] != 3:\n",
    "        invalid.append(i)\n",
    "\n",
    "df.drop(invalid, inplace=True)\n",
    "df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d501fa3",
   "metadata": {},
   "source": [
    "### Creating Training and Testing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a67ac85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the training and testing datasets\n",
    "y1 = df['Diabetes']\n",
    "X1 = df.drop('Diabetes', axis=1)\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2e0fd1",
   "metadata": {},
   "source": [
    "### Creating Training and Testing Dataset with Balanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee4d5d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing the datasets\n",
    "df_pos = df[df['Diabetes']==0]\n",
    "df_neg = df[df['Diabetes']==1]\n",
    "\n",
    "df2 = pd.concat([df_pos.sample(n=len(df_neg), random_state=42), df_neg], axis=0)\n",
    "df2 = df2.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Creating the balanced training and testing datasets\n",
    "y2 = df2['Diabetes']\n",
    "X2 = df2.drop('Diabetes', axis=1)\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58617a7",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da1c765",
   "metadata": {},
   "source": [
    "### Initial Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a9d3080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 0.9326500732064422\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       597\n",
      "           1       0.74      0.71      0.73        86\n",
      "\n",
      "    accuracy                           0.93       683\n",
      "   macro avg       0.85      0.84      0.84       683\n",
      "weighted avg       0.93      0.93      0.93       683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initializing Random Forest Model and fitting the model on the original training set\n",
    "rf_model1 = RandomForestClassifier(random_state=42).fit(X1_train, y1_train)\n",
    "\n",
    "# Making predictions with the Random Forest Model on the test data\n",
    "y1_pred_rf = rf_model1.predict(X1_test)\n",
    "\n",
    "# Evaluating the model's performance\n",
    "print(\"Accuracy on Test Set:\", accuracy_score(y1_test, y1_pred_rf))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y1_test, y1_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c55bf5",
   "metadata": {},
   "source": [
    "### Getting Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e37af715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FFPG', 'HDL', 'LDL', 'FPG', 'Age']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting important features\n",
    "rf_feature_importance = pd.Series(rf_model1.feature_importances_, index=X1_train.columns).sort_values(ascending=False)\n",
    "\n",
    "count = 0\n",
    "rf_selected_features = []\n",
    "\n",
    "for x in range(len(rf_feature_importance)):\n",
    "    if rf_feature_importance[x] > 0.05:\n",
    "        rf_selected_features.append(rf_feature_importance.index[x])\n",
    "    count+=1\n",
    "    \n",
    "rf_selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd31cbe",
   "metadata": {},
   "source": [
    "### Random Forest Model with Balanced Dataset and Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd01b8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 0.8674698795180723\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88        94\n",
      "           1       0.83      0.88      0.85        72\n",
      "\n",
      "    accuracy                           0.87       166\n",
      "   macro avg       0.86      0.87      0.87       166\n",
      "weighted avg       0.87      0.87      0.87       166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting training and testing datasets with only important features from the balanced dataset\n",
    "rf_X2_train = X2_train[rf_selected_features]\n",
    "rf_X2_test = X2_test[rf_selected_features]\n",
    "\n",
    "# Initializing Random Forest Model and fitting the model on the updated training set\n",
    "rf_model2 = RandomForestClassifier(random_state=42).fit(rf_X2_train, y2_train)\n",
    "\n",
    "# Making predictions with the Random Forest Model on the updated test data\n",
    "y2_pred_rf = rf_model2.predict(rf_X2_test)\n",
    "\n",
    "# Evaluating the model's performance\n",
    "print(\"Accuracy on Test Set:\", accuracy_score(y2_test, y2_pred_rf))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y2_test, y2_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e30023",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eab02327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the parameter grid\n",
    "param_grid1 = {\n",
    "    'n_estimators': [50, 100, 150, 250],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'min_samples_split': [5, 10, 20],\n",
    "    'max_depth': [5, 10, 15, 20],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0459019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 150,\n",
       " 'min_samples_split': 10,\n",
       " 'max_features': 'log2',\n",
       " 'max_depth': 5}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Randomized Search to find best hyperparameters\n",
    "random_search1 = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=42), param_distributions=param_grid1, n_iter=10, cv=3, random_state=42)\n",
    "random_search1.fit(rf_X2_train, y2_train)\n",
    "random_search1.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f747de",
   "metadata": {},
   "source": [
    "### Random Forest Model with Balanced Dataset, Important Features and Best HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1e03065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 0.8855421686746988\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90        94\n",
      "           1       0.87      0.86      0.87        72\n",
      "\n",
      "    accuracy                           0.89       166\n",
      "   macro avg       0.88      0.88      0.88       166\n",
      "weighted avg       0.89      0.89      0.89       166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initializing Random Forest Model and fitting the model on the updated training set with best hyperparameters\n",
    "rf_model3 = RandomForestClassifier(n_estimators=150, max_depth=5, max_features='log2', min_samples_split=10, random_state=42).fit(rf_X2_train, y2_train)\n",
    "\n",
    "# Making predictions with the Random Forest Model on the updated test data\n",
    "y3_pred_rf = rf_model3.predict(rf_X2_test)\n",
    "\n",
    "# Evaluating the model's performance\n",
    "print(\"Accuracy on Test Set:\", accuracy_score(y2_test, y3_pred_rf))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y2_test, y3_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da6e6b1",
   "metadata": {},
   "source": [
    "# Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6143da14",
   "metadata": {},
   "source": [
    "### Initial Extreme Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b137ddb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 0.9326500732064422\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       597\n",
      "           1       0.76      0.69      0.72        86\n",
      "\n",
      "    accuracy                           0.93       683\n",
      "   macro avg       0.86      0.83      0.84       683\n",
      "weighted avg       0.93      0.93      0.93       683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initializing Extreme Gradient Boosting Model and fitting the model on the original training set\n",
    "xgb_model1 = XGBClassifier(random_state=42).fit(X1_train, y1_train)\n",
    "\n",
    "# Making predictions with the Extreme Gradient Boosting Model on the test data\n",
    "y1_pred_xgb = xgb_model1.predict(X1_test)\n",
    "\n",
    "# Evaluating the model's performance\n",
    "print(\"Accuracy on Test Set:\", accuracy_score(y1_test, y1_pred_xgb))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y1_test, y1_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa99cddb",
   "metadata": {},
   "source": [
    "### Getting Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d86cc8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FFPG', 'HDL', 'Age', 'FPG']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting important features\n",
    "xgb_feature_importance = pd.Series(xgb_model1.feature_importances_, index=X1_train.columns).sort_values(ascending=False)\n",
    "\n",
    "count = 0\n",
    "xgb_selected_features = []\n",
    "\n",
    "for x in range(len(xgb_feature_importance)):\n",
    "    if xgb_feature_importance[x] > 0.05:\n",
    "        xgb_selected_features.append(xgb_feature_importance.index[x])\n",
    "    count+=1\n",
    "    \n",
    "xgb_selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7540a941",
   "metadata": {},
   "source": [
    "### Extreme Gradient Boosting Model with Balanced Dataset and Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b6f54d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 0.8554216867469879\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87        94\n",
      "           1       0.80      0.89      0.84        72\n",
      "\n",
      "    accuracy                           0.86       166\n",
      "   macro avg       0.85      0.86      0.85       166\n",
      "weighted avg       0.86      0.86      0.86       166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting training and testing datasets with only important features from the balanced dataset\n",
    "xgb_X2_train = X2_train[xgb_selected_features]\n",
    "xgb_X2_test = X2_test[xgb_selected_features]\n",
    "\n",
    "# Initializing Extreme Gradient Boosting Model and fitting the model on the updated training set\n",
    "xgb_model2 = XGBClassifier(random_state=42).fit(xgb_X2_train, y2_train)\n",
    "\n",
    "# Making predictions with the Extreme Gradient Boosting Model on the updated test data\n",
    "y2_pred_xgb = xgb_model2.predict(xgb_X2_test)\n",
    "\n",
    "# Evaluating the model's performance\n",
    "print(\"Accuracy on Test Set:\", accuracy_score(y2_test, y2_pred_xgb))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y2_test, y2_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaae3df",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d80615a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the parameter grid\n",
    "param_grid2 = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0.5, 1, 1.5],\n",
    "    'subsample': [0.7, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.9],\n",
    "    'n_estimators': [100, 150],\n",
    "    'learning_rate': [0.05, 0.1, 0.15]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38ce7f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.7,\n",
       " 'n_estimators': 100,\n",
       " 'min_child_weight': 3,\n",
       " 'max_depth': 3,\n",
       " 'learning_rate': 0.05,\n",
       " 'gamma': 1.5,\n",
       " 'colsample_bytree': 0.7}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Randomized Search to find best hyperparameters\n",
    "random_search2 = RandomizedSearchCV(estimator=XGBClassifier(random_state=42), param_distributions=param_grid2, n_iter=10, cv=3, random_state=42)\n",
    "random_search2.fit(xgb_X2_train, y2_train)\n",
    "random_search2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c11719",
   "metadata": {},
   "source": [
    "### Extreme Gradient Boosting with Balanced Dataset, Important Features and Best HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a7ed0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 0.8855421686746988\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90        94\n",
      "           1       0.87      0.86      0.87        72\n",
      "\n",
      "    accuracy                           0.89       166\n",
      "   macro avg       0.88      0.88      0.88       166\n",
      "weighted avg       0.89      0.89      0.89       166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initializing Extreme Gradient Boosting Model and fitting the model on the updated training set with best hyperparameters\n",
    "xgb_model3 = XGBClassifier(n_estimators=100, gamma=1.5, max_depth=3, min_child_weight=3, subsample=0.7, colsample_bytree=0.7, learning_rate=0.05, random_state=42).fit(xgb_X2_train, y2_train)\n",
    "\n",
    "# Making predictions with the Extreme Gradient Boosting Model on the updated test data\n",
    "y3_pred_xgb = xgb_model3.predict(xgb_X2_test)\n",
    "\n",
    "# Evaluating the model's performance\n",
    "print(\"Accuracy on Test Set:\", accuracy_score(y2_test, y3_pred_xgb))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y2_test, y3_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fdef23",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eb4e08",
   "metadata": {},
   "source": [
    "### Initial Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03f1975a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 0.9341142020497804\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96       597\n",
      "           1       0.80      0.64      0.71        86\n",
      "\n",
      "    accuracy                           0.93       683\n",
      "   macro avg       0.87      0.81      0.84       683\n",
      "weighted avg       0.93      0.93      0.93       683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initializing Logistic Regression Model and fitting the model on the original training set\n",
    "lr_model1 = LogisticRegression(max_iter= 5000, random_state=42).fit(X1_train, y1_train)\n",
    "\n",
    "# Making predictions with the Logistic Regression Model on the test data\n",
    "y1_pred_lr = lr_model1.predict(X1_test)\n",
    "\n",
    "# Evaluating the model's performance\n",
    "print(\"Accuracy on Test Set:\", accuracy_score(y1_test, y1_pred_lr))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y1_test, y1_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ee5707",
   "metadata": {},
   "source": [
    "### Getting Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47cf7fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FPG', 'HDL', 'LDL', 'FFPG', 'family_histroy']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting important features\n",
    "rfe = RFE(lr_model1, n_features_to_select=5).fit(X1_train, y1_train)\n",
    "lr_feature_importance = rfe.support_\n",
    "\n",
    "count = 0\n",
    "lr_selected_features = []\n",
    "\n",
    "for col in X1_train:\n",
    "    if lr_feature_importance[count]:\n",
    "        lr_selected_features.append(col)\n",
    "    count+=1\n",
    "\n",
    "lr_selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82093711",
   "metadata": {},
   "source": [
    "### Logistic Regression Model with Balanced Dataset and Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd95386e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 0.8614457831325302\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88        94\n",
      "           1       0.85      0.83      0.84        72\n",
      "\n",
      "    accuracy                           0.86       166\n",
      "   macro avg       0.86      0.86      0.86       166\n",
      "weighted avg       0.86      0.86      0.86       166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting training and testing datasets with only important features from the balanced dataset\n",
    "lr_X2_train = X2_train[lr_selected_features]\n",
    "lr_X2_test = X2_test[lr_selected_features]\n",
    "\n",
    "# Initializing Logistic Regression Model and fitting the model on the updated training set\n",
    "lr_model2 = LogisticRegression(max_iter= 5000, random_state=42).fit(lr_X2_train, y2_train)\n",
    "\n",
    "# Making predictions with the Logistic Regression Model on the updated test data\n",
    "y2_pred_lr = lr_model2.predict(lr_X2_test)\n",
    "\n",
    "# Evaluating the model's performance\n",
    "print(\"Accuracy on Test Set:\", accuracy_score(y2_test, y2_pred_lr))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y2_test, y2_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ad676f",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "334858e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the parameter grid\n",
    "param_grid3 = {\n",
    "    'solver': ['newton-cg', 'newton-cholesky', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'penalty': ['l2'],\n",
    "    'C': [100, 10, 1, 0.1, 0.01, 0.001],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d18d2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'newton-cholesky', 'penalty': 'l2', 'C': 0.1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Randomized Search to find best hyperparameters\n",
    "random_search3 = RandomizedSearchCV(estimator=LogisticRegression(max_iter=5000, random_state=42), param_distributions=param_grid3, n_iter=25, cv=3, random_state=42)\n",
    "random_search3.fit(lr_X2_train, y2_train)\n",
    "random_search3.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3668a8",
   "metadata": {},
   "source": [
    "### Logistic Regression Model with Balanced Dataset, Important Features and Best HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a5d889b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 0.8734939759036144\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89        94\n",
      "           1       0.87      0.83      0.85        72\n",
      "\n",
      "    accuracy                           0.87       166\n",
      "   macro avg       0.87      0.87      0.87       166\n",
      "weighted avg       0.87      0.87      0.87       166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initializing Logistic Regression Model and fitting the model on the updated training set with best hyperparameters\n",
    "lr_model3 = LogisticRegression(penalty='l2', C=0.1, solver='newton-cholesky', max_iter= 5000, random_state=42).fit(lr_X2_train, y2_train)\n",
    "\n",
    "# Making predictions with the Logistic Regression Model on the updated test data\n",
    "y3_pred_lr = lr_model3.predict(lr_X2_test)\n",
    "\n",
    "# Evaluating the model's performance\n",
    "print(\"Accuracy on Test Set:\", accuracy_score(y2_test, y3_pred_lr))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y2_test, y3_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93fd0a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
