{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fb5bef0",
   "metadata": {},
   "source": [
    "# Converting Data into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c228e3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>never</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>current</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
       "0  Female  80.0             0              1           never  25.19   \n",
       "1  Female  54.0             0              0         No Info  27.32   \n",
       "2    Male  28.0             0              0           never  27.32   \n",
       "3  Female  36.0             0              0         current  23.45   \n",
       "4    Male  76.0             1              1         current  20.14   \n",
       "\n",
       "   HbA1c_level  blood_glucose_level  diabetes  \n",
       "0          6.6                  140         0  \n",
       "1          6.6                   80         0  \n",
       "2          5.7                  158         0  \n",
       "3          5.0                  155         0  \n",
       "4          4.8                  155         0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data_path = 'diabetes_prediction_dataset.csv'  # Make sure to replace this with the actual path to your dataset\n",
    "diabetes_data = pd.read_csv(data_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "diabetes_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8be6413",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7f485c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>gender_Other</th>\n",
       "      <th>smoking_No Info</th>\n",
       "      <th>smoking_current</th>\n",
       "      <th>smoking_ever</th>\n",
       "      <th>smoking_former</th>\n",
       "      <th>smoking_never</th>\n",
       "      <th>smoking_not current</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  hypertension  heart_disease    bmi  HbA1c_level  blood_glucose_level  \\\n",
       "0  80.0             0              1  25.19          6.6                  140   \n",
       "1  54.0             0              0  27.32          6.6                   80   \n",
       "2  28.0             0              0  27.32          5.7                  158   \n",
       "3  36.0             0              0  23.45          5.0                  155   \n",
       "4  76.0             1              1  20.14          4.8                  155   \n",
       "\n",
       "   diabetes  gender_Female  gender_Male  gender_Other  smoking_No Info  \\\n",
       "0         0           True        False         False            False   \n",
       "1         0           True        False         False             True   \n",
       "2         0          False         True         False            False   \n",
       "3         0           True        False         False            False   \n",
       "4         0          False         True         False            False   \n",
       "\n",
       "   smoking_current  smoking_ever  smoking_former  smoking_never  \\\n",
       "0            False         False           False           True   \n",
       "1            False         False           False          False   \n",
       "2            False         False           False           True   \n",
       "3             True         False           False          False   \n",
       "4             True         False           False          False   \n",
       "\n",
       "   smoking_not current  \n",
       "0                False  \n",
       "1                False  \n",
       "2                False  \n",
       "3                False  \n",
       "4                False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_data_encoded = pd.get_dummies(diabetes_data, columns=['gender'], prefix='gender')\n",
    "\n",
    "diabetes_data_encoded = pd.get_dummies(diabetes_data_encoded, columns=['smoking_history'], prefix='smoking')\n",
    "\n",
    "# Displaying the first few rows of the DataFrame to show the result of one-hot encoding\n",
    "diabetes_data_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774baee9",
   "metadata": {},
   "source": [
    "# Initial Training Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59f94a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 0.97005\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     18292\n",
      "           1       0.95      0.69      0.80      1708\n",
      "\n",
      "    accuracy                           0.97     20000\n",
      "   macro avg       0.96      0.84      0.89     20000\n",
      "weighted avg       0.97      0.97      0.97     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Preparing the data\n",
    "X = diabetes_data_encoded.drop('diabetes', axis=1)\n",
    "y = diabetes_data_encoded['diabetes']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initializing the Random Forest classifier\n",
    "rf_all = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fitting the model on the training set\n",
    "rf_all.fit(X_train, y_train)\n",
    "\n",
    "# Predicting diabetes with the Random Forest classifier on the test set\n",
    "y_pred = rf_all.predict(X_test)\n",
    "\n",
    "# Evaluating the model's performance\n",
    "print(\"Accuracy on Test Set:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591d4e9a",
   "metadata": {},
   "source": [
    "# Importance Feature Search Using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d87edcd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HbA1c_level            0.405538\n",
       "blood_glucose_level    0.314021\n",
       "bmi                    0.125966\n",
       "age                    0.104367\n",
       "hypertension           0.015910\n",
       "heart_disease          0.011052\n",
       "smoking_No Info        0.004464\n",
       "smoking_former         0.003788\n",
       "smoking_never          0.003326\n",
       "smoking_current        0.002543\n",
       "gender_Male            0.002361\n",
       "gender_Female          0.002344\n",
       "smoking_not current    0.002226\n",
       "smoking_ever           0.002092\n",
       "gender_Other           0.000003\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = diabetes_data_encoded.drop('diabetes', axis=1)\n",
    "y = diabetes_data_encoded['diabetes']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d43121",
   "metadata": {},
   "source": [
    "# Checking For Imbalance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd0299b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diabetes\n",
       "0    0.915\n",
       "1    0.085\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the balance of the target variable 'diabetes'\n",
    "target_balance = diabetes_data_encoded['diabetes'].value_counts(normalize=True)\n",
    "\n",
    "target_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74706fd",
   "metadata": {},
   "source": [
    "# Second Training of Random Forest Model with Important Features and Balance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a3a1c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 0.8970588235294118\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90      1687\n",
      "           1       0.89      0.90      0.90      1713\n",
      "\n",
      "    accuracy                           0.90      3400\n",
      "   macro avg       0.90      0.90      0.90      3400\n",
      "weighted avg       0.90      0.90      0.90      3400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Identify the number of instances with diabetes=1\n",
    "n_diabetes_pos = diabetes_data_encoded[diabetes_data_encoded['diabetes'] == 1].shape[0]\n",
    "\n",
    "# Downsample the instances where diabetes=0 to match the number of diabetes=1\n",
    "df_majority = diabetes_data_encoded[diabetes_data_encoded['diabetes'] == 0]\n",
    "df_minority = diabetes_data_encoded[diabetes_data_encoded['diabetes'] == 1]\n",
    "\n",
    "df_majority_downsampled_8500 = resample(df_majority, \n",
    "                                        replace=False,    # sample without replacement\n",
    "                                        n_samples=8500,   # to match exactly 8500 samples for diabetes class\n",
    "                                        random_state=123) # reproducible results\n",
    "\n",
    "# Combine the downsampled majority class with the original minority class\n",
    "df_balanced_8500 = pd.concat([df_majority_downsampled_8500, df_minority])\n",
    "\n",
    "# Split the balanced dataset into features (X) and target variable (y) using only the important features\n",
    "important_features = ['HbA1c_level', 'blood_glucose_level', 'bmi', 'age']\n",
    "\n",
    "X_balanced_8500 = df_balanced_8500[important_features]\n",
    "y_balanced_8500 = df_balanced_8500['diabetes']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_bal_8500, X_test_bal_8500, y_train_bal_8500, y_test_bal_8500 = train_test_split(X_balanced_8500, y_balanced_8500, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_balanced_8500 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model on the balanced dataset\n",
    "rf_balanced_8500.fit(X_train_bal_8500, y_train_bal_8500)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred_bal_8500 = rf_balanced_8500.predict(X_test_bal_8500)\n",
    "\n",
    "# Generate classification report on the balanced dataset\n",
    "print(\"Accuracy on Test Set:\", accuracy_score(y_test_bal_8500, y_pred_bal_8500))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_bal_8500, y_pred_bal_8500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad87a07c",
   "metadata": {},
   "source": [
    "# HyperParameter GridSearching for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cca073a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 12,\n",
       "  'max_features': 'sqrt',\n",
       "  'min_samples_split': 8,\n",
       "  'n_estimators': 120},\n",
       " 0.9066178352653335)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define the parameter grid for Random Search\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': randint(10, 50),\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Initialize the Random Search model\n",
    "random_search = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,  # Number of parameter settings that are sampled. Increase for better results but longer computation.\n",
    "    cv=3,       # Cross-validation strategy. Increase for more reliable estimates but longer computation.\n",
    "    random_state=42,\n",
    "    n_jobs=-1   # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit the model on the balanced dataset\n",
    "random_search.fit(X_train_bal_8500, y_train_bal_8500)\n",
    "\n",
    "# Best parameters found by Random Search\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "best_params, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaa851b",
   "metadata": {},
   "source": [
    "# Final Training of Random Forest Model with Best HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bba6753e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 0.9073529411764706\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91      1687\n",
      "           1       0.90      0.92      0.91      1713\n",
      "\n",
      "    accuracy                           0.91      3400\n",
      "   macro avg       0.91      0.91      0.91      3400\n",
      "weighted avg       0.91      0.91      0.91      3400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adjusted hyperparameters\n",
    "\n",
    "rf_balanced_adjusted = RandomForestClassifier(\n",
    "    n_estimators=120,  # Increased from 100 to 200\n",
    "    max_depth=12,       # Increased depth\n",
    "    min_samples_split=8,  # Require more samples to split\n",
    "    random_state=42,\n",
    "    max_features = 'sqrt',\n",
    "    class_weight= 'balanced'\n",
    ")\n",
    "\n",
    "# Fit the model on the balanced dataset with adjusted hyperparameters\n",
    "rf_balanced_adjusted.fit(X_train_bal_8500, y_train_bal_8500)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred_bal_adjusted = rf_balanced_adjusted.predict(X_test_bal_8500)\n",
    "\n",
    "# Calculate accuracy and generate classification report on the balanced dataset\n",
    "accuracy_bal_adjusted = accuracy_score(y_test_bal_8500, y_pred_bal_adjusted)\n",
    "report_bal_adjusted = classification_report(y_test_bal_8500, y_pred_bal_adjusted)\n",
    "\n",
    "accuracy_bal_adjusted, report_bal_adjusted\n",
    "\n",
    "print(\"Accuracy on Test Set:\", accuracy_bal_adjusted)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report_bal_adjusted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18a6bb0",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0207b30",
   "metadata": {},
   "source": [
    "# Initial Training of Extreme Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d7b1254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 0.97145\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     18292\n",
      "           1       0.95      0.70      0.81      1708\n",
      "\n",
      "    accuracy                           0.97     20000\n",
      "   macro avg       0.96      0.85      0.90     20000\n",
      "weighted avg       0.97      0.97      0.97     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Preparing the data\n",
    "X = diabetes_data_encoded.drop('diabetes', axis=1)\n",
    "y = diabetes_data_encoded['diabetes']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initializing the XGBoost classifier\n",
    "xgb_classifier = XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Fitting the model on the training set\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting diabetes with the XGBoost classifier on the test set\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluating the model's performance\n",
    "print(\"Accuracy on Test Set:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0732036",
   "metadata": {},
   "source": [
    "# Second Training of Extreme Gradient Boosting Model with Important Features and Balance DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd8bcf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 0.8991176470588236\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.90      1687\n",
      "           1       0.89      0.91      0.90      1713\n",
      "\n",
      "    accuracy                           0.90      3400\n",
      "   macro avg       0.90      0.90      0.90      3400\n",
      "weighted avg       0.90      0.90      0.90      3400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Balancing the dataset\n",
    "n_diabetes_pos = diabetes_data_encoded[diabetes_data_encoded['diabetes'] == 1].shape[0]\n",
    "df_majority = diabetes_data_encoded[diabetes_data_encoded['diabetes'] == 0]\n",
    "df_minority = diabetes_data_encoded[diabetes_data_encoded['diabetes'] == 1]\n",
    "\n",
    "df_majority_downsampled_8500 = resample(df_majority, \n",
    "                                        replace=False,    # sample without replacement\n",
    "                                        n_samples=8500,   # to match minority class count\n",
    "                                        random_state=123) # reproducible results\n",
    "\n",
    "df_balanced_8500 = pd.concat([df_majority_downsampled_8500, df_minority])\n",
    "\n",
    "# Selecting important features\n",
    "important_features = ['HbA1c_level', 'blood_glucose_level', 'bmi', 'age']\n",
    "X_balanced_8500 = df_balanced_8500[important_features]\n",
    "y_balanced_8500 = df_balanced_8500['diabetes']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train_bal_8500, X_test_bal_8500, y_train_bal_8500, y_test_bal_8500 = train_test_split(X_balanced_8500, y_balanced_8500, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initializing and training the XGBoost classifier\n",
    "xgb_classifier_bal_8500 = XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_classifier_bal_8500.fit(X_train_bal_8500, y_train_bal_8500)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred_bal_8500 = xgb_classifier_bal_8500.predict(X_test_bal_8500)\n",
    "\n",
    "# Generating and printing the classification report and accuracy\n",
    "print(\"Accuracy on Test Set:\", accuracy_score(y_test_bal_8500, y_pred_bal_8500))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_bal_8500, y_pred_bal_8500))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3619da",
   "metadata": {},
   "source": [
    "# Final Training of Extreme Gradient Boosting with Best HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "175c1ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best Parameters: {'subsample': 0.9, 'n_estimators': 150, 'min_child_weight': 5, 'max_depth': 5, 'learning_rate': 0.15, 'gamma': 1.5, 'colsample_bytree': 0.9}\n",
      "Accuracy on Test Set: 0.9061764705882352\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90      1687\n",
      "           1       0.90      0.92      0.91      1713\n",
      "\n",
      "    accuracy                           0.91      3400\n",
      "   macro avg       0.91      0.91      0.91      3400\n",
      "weighted avg       0.91      0.91      0.91      3400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Define the parameter distribution to sample from\n",
    "param_dist = {\n",
    "    'max_depth': [3, 5, 7],                     # Limits the depth of the tree\n",
    "    'min_child_weight': [1, 3, 5],              # Minimum sum of instance weight (hessian) needed in a child\n",
    "    'gamma': [0.5, 1, 1.5],                     # Minimum loss reduction required to make a further partition on a leaf node\n",
    "    'subsample': [0.7, 0.9],                    # Subsample ratio of the training instances\n",
    "    'colsample_bytree': [0.7, 0.9],             # Subsample ratio of columns when constructing each tree\n",
    "    'n_estimators': [100, 150],                 # Number of trees in the forest\n",
    "    'learning_rate': [0.05, 0.1, 0.15]          # Step size shrinkage used to prevent overfitting\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier and RandomizedSearchCV\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "random_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_dist, \n",
    "                                   n_iter=10, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit RandomizedSearchCV to the training data\n",
    "random_search.fit(X_train_bal_8500, y_train_bal_8500)\n",
    "\n",
    "# Extract the best model\n",
    "best_xgb = random_search.best_estimator_\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred_best = best_xgb.predict(X_test_bal_8500)\n",
    "\n",
    "# Evaluate the best model\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Accuracy on Test Set:\", accuracy_score(y_test_bal_8500, y_pred_best))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_bal_8500, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41869c13",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c24c541",
   "metadata": {},
   "source": [
    "# Initial Training of Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f565b192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 0.959\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     18292\n",
      "           1       0.86      0.62      0.72      1708\n",
      "\n",
      "    accuracy                           0.96     20000\n",
      "   macro avg       0.91      0.80      0.85     20000\n",
      "weighted avg       0.96      0.96      0.96     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avinash Roopnarine\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Preparing the data\n",
    "X = diabetes_data_encoded.drop('diabetes', axis=1)\n",
    "y = diabetes_data_encoded['diabetes']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initializing the Logistic Regression classifier\n",
    "lr_classifier = LogisticRegression(random_state=42, max_iter=1000)  # Increased max_iter for convergence\n",
    "\n",
    "# Fitting the model on the training set\n",
    "lr_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting diabetes with the Logistic Regression classifier on the test set\n",
    "y_pred = lr_classifier.predict(X_test)\n",
    "\n",
    "# Evaluating the model's performance\n",
    "print(\"Accuracy on Test Set:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d9381",
   "metadata": {},
   "source": [
    "# Second Training of Logistic Regression Model with Important Features and Balance DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "753f52a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 0.8835294117647059\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88      1687\n",
      "           1       0.89      0.88      0.88      1713\n",
      "\n",
      "    accuracy                           0.88      3400\n",
      "   macro avg       0.88      0.88      0.88      3400\n",
      "weighted avg       0.88      0.88      0.88      3400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd  # Ensure pandas is imported to handle data operations\n",
    "\n",
    "# Balancing the dataset\n",
    "n_diabetes_pos = diabetes_data_encoded[diabetes_data_encoded['diabetes'] == 1].shape[0]\n",
    "df_majority = diabetes_data_encoded[diabetes_data_encoded['diabetes'] == 0]\n",
    "df_minority = diabetes_data_encoded[diabetes_data_encoded['diabetes'] == 1]\n",
    "\n",
    "df_majority_downsampled_8500 = resample(df_majority, \n",
    "                                        replace=False,    # sample without replacement\n",
    "                                        n_samples=8500,   # to match minority class count\n",
    "                                        random_state=123) # reproducible results\n",
    "\n",
    "df_balanced_8500 = pd.concat([df_majority_downsampled_8500, df_minority])\n",
    "\n",
    "# Selecting important features\n",
    "important_features = ['HbA1c_level', 'blood_glucose_level', 'bmi', 'age']\n",
    "X_balanced_8500 = df_balanced_8500[important_features]\n",
    "y_balanced_8500 = df_balanced_8500['diabetes']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train_bal_8500, X_test_bal_8500, y_train_bal_8500, y_test_bal_8500 = train_test_split(X_balanced_8500, y_balanced_8500, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initializing and training the Logistic Regression classifier\n",
    "lr_classifier_bal_8500 = LogisticRegression(max_iter=1000, random_state=42)  # Increased max_iter for convergence\n",
    "lr_classifier_bal_8500.fit(X_train_bal_8500, y_train_bal_8500)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred_bal_8500 = lr_classifier_bal_8500.predict(X_test_bal_8500)\n",
    "\n",
    "# Generating and printing the classification report and accuracy\n",
    "print(\"Accuracy on Test Set:\", accuracy_score(y_test_bal_8500, y_pred_bal_8500))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_bal_8500, y_pred_bal_8500))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a755fba",
   "metadata": {},
   "source": [
    "# Final Training of Extreme Gradient Boosting with Best HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db6a9b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best Parameters: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy on Test Set: 0.8844117647058823\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88      1687\n",
      "           1       0.89      0.88      0.88      1713\n",
      "\n",
      "    accuracy                           0.88      3400\n",
      "   macro avg       0.88      0.88      0.88      3400\n",
      "weighted avg       0.88      0.88      0.88      3400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'diabetes_data_encoded' is already loaded and available\n",
    "\n",
    "# Balancing the dataset\n",
    "df_majority = diabetes_data_encoded[diabetes_data_encoded['diabetes'] == 0]\n",
    "df_minority = diabetes_data_encoded[diabetes_data_encoded['diabetes'] == 1]\n",
    "df_majority_downsampled_8500 = resample(df_majority, \n",
    "                                        replace=False,    # sample without replacement\n",
    "                                        n_samples=8500,   # to match minority class count\n",
    "                                        random_state=123) # reproducible results\n",
    "df_balanced_8500 = pd.concat([df_majority_downsampled_8500, df_minority])\n",
    "\n",
    "# Selecting important features\n",
    "important_features = ['HbA1c_level', 'blood_glucose_level', 'bmi', 'age']\n",
    "X_balanced_8500 = df_balanced_8500[important_features]\n",
    "y_balanced_8500 = df_balanced_8500['diabetes']\n",
    "\n",
    "# Splitting the data\n",
    "X_train_bal_8500, X_test_bal_8500, y_train_bal_8500, y_test_bal_8500 = train_test_split(X_balanced_8500, y_balanced_8500, test_size=0.2, random_state=42)\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'penalty': ['l1', 'l2'],               # Types of regularization\n",
    "    'solver': ['liblinear', 'saga']        # Solvers that support l1 penalties\n",
    "}\n",
    "\n",
    "# GridSearchCV setup\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=1000, random_state=42), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train_bal_8500, y_train_bal_8500)\n",
    "\n",
    "# Best model\n",
    "best_lr = grid_search.best_estimator_\n",
    "\n",
    "# Making predictions and evaluating the best model\n",
    "y_pred_best = best_lr.predict(X_test_bal_8500)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Accuracy on Test Set:\", accuracy_score(y_test_bal_8500, y_pred_best))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_bal_8500, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267e7550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
