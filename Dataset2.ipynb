{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "LOADING DATASET"
      ],
      "metadata": {
        "id": "-aUlN0x8-gwQ"
      },
      "id": "-aUlN0x8-gwQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46184a58",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46184a58",
        "outputId": "cfc6e812-4ebe-4d12-e2ce-2b76abe006b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
            "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
            "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
            "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
            "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
            "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
            "\n",
            "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
            "0                   0.0           0.0     0.0  ...            1.0   \n",
            "1                   0.0           1.0     0.0  ...            0.0   \n",
            "2                   0.0           0.0     1.0  ...            1.0   \n",
            "3                   0.0           1.0     1.0  ...            1.0   \n",
            "4                   0.0           1.0     1.0  ...            1.0   \n",
            "\n",
            "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
            "0          0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n",
            "1          1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n",
            "2          1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n",
            "3          0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n",
            "4          0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n",
            "\n",
            "   Income  \n",
            "0     3.0  \n",
            "1     1.0  \n",
            "2     8.0  \n",
            "3     6.0  \n",
            "4     4.0  \n",
            "\n",
            "[5 rows x 22 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the uploaded file into a DataFrame\n",
        "df = pd.read_csv('diabetes_012_health_indicators_BRFSS2015.csv')\n",
        "\n",
        "# Display the unique values for each column in the DataFrame\n",
        "unique_values = {column: df[column].unique() for column in df.columns}\n",
        "#unique_values\n",
        "print(df.head());"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CLEANING DATASET"
      ],
      "metadata": {
        "id": "WDOc0GcRD35T"
      },
      "id": "WDOc0GcRD35T"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "# Initialize MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit and transform the data\n",
        "df['BMI_scaled'] = scaler.fit_transform(df[['BMI']])\n",
        "df.drop(columns=['BMI'], inplace=True)\n",
        "df['Age_scaled'] = scaler.fit_transform(df[['Age']])\n",
        "df.drop(columns=['Age'], inplace=True)\n",
        "\n",
        "\n",
        "# Dropping all rows with prediabetes ('1') from the dataset\n",
        "df_binary = df[df['Diabetes_012'] != 1]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kt3SqfG8D-Yc"
      },
      "id": "kt3SqfG8D-Yc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING RANDOM FOREST"
      ],
      "metadata": {
        "id": "HGD0hIUfEgYT"
      },
      "id": "HGD0hIUfEgYT"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "\n",
        "# Adjusting the target for binary classification (0: No Diabetes, 2: Diabetes)\n",
        "# Note: Since we're excluding prediabetes, we'll map '2' (diabetes) to '1' for the binary classification\n",
        "y_binary_no_prediabetes = df_binary['Diabetes_012'].replace({2: 1})\n",
        "\n",
        "# Features remain the same, but filtered to match the rows of the updated target\n",
        "X_binary_no_prediabetes = df_binary.drop('Diabetes_012', axis=1)\n",
        "\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary_no_prediabetes, y_binary_no_prediabetes, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initializing the Random Forest classifier\n",
        "rf_all = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fitting the model on the training set\n",
        "rf_all.fit(X_train, y_train)\n",
        "\n",
        "# Predicting diabetes with the Random Forest classifier on the test set\n",
        "y_pred = rf_all.predict(X_test)\n",
        "\n",
        "# Evaluating the model's performance\n",
        "print(\"Accuracy on Test Set:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSm-V1wkEkd9",
        "outputId": "24c2bab1-1b0e-4336-8fe6-b17c90166546"
      },
      "id": "CSm-V1wkEkd9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Test Set: 0.8589841397309778\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.97      0.92     42777\n",
            "         1.0       0.50      0.20      0.28      7033\n",
            "\n",
            "    accuracy                           0.86     49810\n",
            "   macro avg       0.69      0.58      0.60     49810\n",
            "weighted avg       0.83      0.86      0.83     49810\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHECKING FOR IMBALANCE DATASET"
      ],
      "metadata": {
        "id": "JNFBHCmbFoAy"
      },
      "id": "JNFBHCmbFoAy"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "diabetes_counts = df_binary['Diabetes_012'].value_counts(normalize=True)\n",
        "\n",
        "diabetes_counts\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NZmdmNCFuKz",
        "outputId": "d8a04173-d8de-4475-e528-c1feefaedde1"
      },
      "id": "-NZmdmNCFuKz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Diabetes_012\n",
              "0.0    0.858076\n",
              "2.0    0.141924\n",
              "Name: proportion, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SECOND TRAINING OF RANDOM FOREST MODEL WITH IMPORTANT FEATURES AND BALANCED DATASET"
      ],
      "metadata": {
        "id": "ZjVzIrVMGVsY"
      },
      "id": "ZjVzIrVMGVsY"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "\n",
        "# Identify the number of instances with diabetes=1\n",
        "n_diabetes_pos = df_binary[df_binary['Diabetes_012'] == 2].shape[0]\n",
        "\n",
        "# Downsample the instances where diabetes=0 to match the number of diabetes=1\n",
        "df_majority = df_binary[df_binary['Diabetes_012'] == 0]\n",
        "df_minority = df_binary[df_binary['Diabetes_012'] == 2]\n",
        "\n",
        "df_majority_downsampled_8500 = resample(df_majority,\n",
        "                                        replace=False,    # sample without replacement\n",
        "                                        n_samples=8500,   # to match exactly 8500 samples for diabetes class\n",
        "                                        random_state=123) # reproducible results\n",
        "\n",
        "# Combine the downsampled majority class with the original minority class\n",
        "df_balanced_8500 = pd.concat([df_majority_downsampled_8500, df_minority])\n",
        "\n",
        "# Split the balanced dataset into features (X) and target variable (y) using only the important features\n",
        "important_features = ['HighBP', 'GenHlth', 'HighChol', 'Age_scaled', 'DiffWalk', 'BMI_scaled']\n",
        "\n",
        "X_balanced_8500 = df_balanced_8500[important_features]\n",
        "y_balanced_8500 = df_balanced_8500['Diabetes_012'].replace({2: 1})\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_bal_8500, X_test_bal_8500, y_train_bal_8500, y_test_bal_8500 = train_test_split(X_balanced_8500, y_balanced_8500, test_size=0.2, random_state=42)\n",
        "rf_balanced_8500 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model on the balanced dataset\n",
        "rf_balanced_8500.fit(X_train_bal_8500, y_train_bal_8500)\n",
        "\n",
        "# Predict on the testing set\n",
        "y_pred_bal_8500 = rf_balanced_8500.predict(X_test_bal_8500)\n",
        "\n",
        "# Generate classification report on the balanced dataset\n",
        "print(\"Accuracy on Test Set:\", accuracy_score(y_test_bal_8500, y_pred_bal_8500))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_bal_8500, y_pred_bal_8500))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fyhDu4MGfkz",
        "outputId": "1fed167a-33b7-40a7-c71e-663edcfc5b9b"
      },
      "id": "3fyhDu4MGfkz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Test Set: 0.8232611174458381\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.59      0.38      0.46      1759\n",
            "         1.0       0.86      0.93      0.89      7011\n",
            "\n",
            "    accuracy                           0.82      8770\n",
            "   macro avg       0.73      0.66      0.68      8770\n",
            "weighted avg       0.80      0.82      0.81      8770\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HYPERPARAMETER TUNING"
      ],
      "metadata": {
        "id": "QaUhHXCjLHAh"
      },
      "id": "QaUhHXCjLHAh"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Define the parameter grid for Random Search\n",
        "param_dist = {\n",
        "    'n_estimators': randint(100, 500),\n",
        "    'max_depth': randint(10, 50),\n",
        "    'min_samples_split': randint(2, 20),\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "# Initialize the Random Search model\n",
        "random_search = RandomizedSearchCV(\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,  # Number of parameter settings that are sampled. Increase for better results but longer computation.\n",
        "    cv=3,       # Cross-validation strategy. Increase for more reliable estimates but longer computation.\n",
        "    random_state=42,\n",
        "    n_jobs=-1   # Use all available cores\n",
        ")\n",
        "\n",
        "# Fit the model on the balanced dataset\n",
        "random_search.fit(X_train_bal_8500, y_train_bal_8500)\n",
        "\n",
        "# Best parameters found by Random Search\n",
        "best_params = random_search.best_params_\n",
        "best_score = random_search.best_score_\n",
        "\n",
        "best_params, best_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx479YkTLJwp",
        "outputId": "5a751e8b-7d4d-4973-cf2b-c6adc8edaec3"
      },
      "id": "nx479YkTLJwp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'max_depth': 12,\n",
              "  'max_features': 'sqrt',\n",
              "  'min_samples_split': 8,\n",
              "  'n_estimators': 120},\n",
              " 0.8488425133994754)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINAL TRAINING"
      ],
      "metadata": {
        "id": "foP0ETL-LpKB"
      },
      "id": "foP0ETL-LpKB"
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjusted hyperparameters\n",
        "\n",
        "rf_balanced_adjusted = RandomForestClassifier(\n",
        "    n_estimators=120,\n",
        "    max_depth=12,\n",
        "    min_samples_split=8,\n",
        "    random_state=42,\n",
        "    max_features = 'sqrt',\n",
        "    class_weight= 'balanced'\n",
        ")\n",
        "\n",
        "# Fit the model on the balanced dataset with adjusted hyperparameters\n",
        "rf_balanced_adjusted.fit(X_train_bal_8500, y_train_bal_8500)\n",
        "\n",
        "# Predict on the testing set\n",
        "y_pred_bal_adjusted = rf_balanced_adjusted.predict(X_test_bal_8500)\n",
        "\n",
        "# Calculate accuracy and generate classification report on the balanced dataset\n",
        "accuracy_bal_adjusted = accuracy_score(y_test_bal_8500, y_pred_bal_adjusted)\n",
        "report_bal_adjusted = classification_report(y_test_bal_8500, y_pred_bal_adjusted)\n",
        "\n",
        "accuracy_bal_adjusted, report_bal_adjusted\n",
        "\n",
        "print(\"Accuracy on Test Set:\", accuracy_bal_adjusted)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report_bal_adjusted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okx44dyELpZF",
        "outputId": "9642263e-4711-4613-ff2c-5944a8858cc0"
      },
      "id": "okx44dyELpZF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Test Set: 0.7850627137970353\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.47      0.60      0.53      1759\n",
            "         1.0       0.89      0.83      0.86      7011\n",
            "\n",
            "    accuracy                           0.79      8770\n",
            "   macro avg       0.68      0.72      0.70      8770\n",
            "weighted avg       0.81      0.79      0.79      8770\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INITIAL TRAINING FOR EXTREME GRADIENT BOOSTING MODEL"
      ],
      "metadata": {
        "id": "92N6ZTFtMpCE"
      },
      "id": "92N6ZTFtMpCE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ee1c224",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ee1c224",
        "outputId": "10ba4062-c653-4a97-ccdc-c60c629d34f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Test Set: 0.8655089339490062\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.98      0.93     42777\n",
            "         1.0       0.57      0.20      0.29      7033\n",
            "\n",
            "    accuracy                           0.87     49810\n",
            "   macro avg       0.72      0.59      0.61     49810\n",
            "weighted avg       0.84      0.87      0.84     49810\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Adjusting the target for binary classification (0: No Diabetes, 2: Diabetes)\n",
        "# Note: Since we're excluding prediabetes, we'll map '2' (diabetes) to '1' for the binary classification\n",
        "y_binary_no_prediabetes = df_binary['Diabetes_012'].replace({2: 1})\n",
        "\n",
        "# Features remain the same, but filtered to match the rows of the updated target\n",
        "X_binary_no_prediabetes = df_binary.drop('Diabetes_012', axis=1)\n",
        "\n",
        "# Splitting the data into training and test sets\n",
        "X_train_bin_np, X_test_bin_np, y_train_bin_np, y_test_bin_np = train_test_split(\n",
        "    X_binary_no_prediabetes,\n",
        "    y_binary_no_prediabetes,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Reinitializing and fitting the XGBoost model for the adjusted binary classification\n",
        "model_bin_np = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "model_bin_np.fit(X_train_bin_np, y_train_bin_np)\n",
        "\n",
        "# Making predictions on the test set\n",
        "y_pred_bin_np = model_bin_np.predict(X_test_bin_np)\n",
        "\n",
        "# Calculating accuracy on the test set\n",
        "accuracy_bin_np = accuracy_score(y_test_bin_np, y_pred_bin_np)\n",
        "\n",
        "# Generating classification report for the binary classification\n",
        "report_bin_np = classification_report(y_test_bin_np, y_pred_bin_np)\n",
        "\n",
        "print(\"Accuracy on Test Set:\", accuracy_bin_np)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report_bin_np)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SECOND TRAINING"
      ],
      "metadata": {
        "id": "dY-wyuuVNPIl"
      },
      "id": "dY-wyuuVNPIl"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Balancing the dataset\n",
        "# Identify the number of instances with diabetes=1\n",
        "n_diabetes_pos = df_binary[df_binary['Diabetes_012'] == 2].shape[0]\n",
        "\n",
        "# Downsample the instances where diabetes=0 to match the number of diabetes=1\n",
        "df_majority = df_binary[df_binary['Diabetes_012'] == 0]\n",
        "df_minority = df_binary[df_binary['Diabetes_012'] == 2]\n",
        "\n",
        "df_majority_downsampled_8500 = resample(df_majority,\n",
        "                                        replace=False,    # sample without replacement\n",
        "                                        n_samples=8500,   # to match minority class count\n",
        "                                        random_state=123) # reproducible results\n",
        "\n",
        "df_balanced_8500 = pd.concat([df_majority_downsampled_8500, df_minority])\n",
        "\n",
        "# Selecting important features\n",
        "important_features = ['HighBP', 'GenHlth', 'HighChol', 'Age_scaled', 'DiffWalk', 'BMI_scaled']\n",
        "X_balanced_8500 = df_balanced_8500[important_features]\n",
        "y_balanced_8500 = df_balanced_8500['Diabetes_012'].replace({2: 1})\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train_bal_8500, X_test_bal_8500, y_train_bal_8500, y_test_bal_8500 = train_test_split(X_balanced_8500, y_balanced_8500, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initializing and training the XGBoost classifier\n",
        "xgb_classifier_bal_8500 = XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "xgb_classifier_bal_8500.fit(X_train_bal_8500, y_train_bal_8500)\n",
        "\n",
        "# Making predictions on the test set\n",
        "y_pred_bal_8500 = xgb_classifier_bal_8500.predict(X_test_bal_8500)\n",
        "\n",
        "# Generating and printing the classification report and accuracy\n",
        "print(\"Accuracy on Test Set:\", accuracy_score(y_test_bal_8500, y_pred_bal_8500))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_bal_8500, y_pred_bal_8500))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN37K6Y5NPXJ",
        "outputId": "1586fedc-39b8-42c2-f17d-46498abb9c4f"
      },
      "id": "yN37K6Y5NPXJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Test Set: 0.8449258836944128\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.71      0.38      0.50      1759\n",
            "         1.0       0.86      0.96      0.91      7011\n",
            "\n",
            "    accuracy                           0.84      8770\n",
            "   macro avg       0.79      0.67      0.70      8770\n",
            "weighted avg       0.83      0.84      0.83      8770\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINAL TRAINING"
      ],
      "metadata": {
        "id": "pkY9CuGYOFDM"
      },
      "id": "pkY9CuGYOFDM"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Define the parameter distribution to sample from\n",
        "param_dist = {\n",
        "    'max_depth': [3, 5, 7],                     # Limits the depth of the tree\n",
        "    'min_child_weight': [1, 3, 5],              # Minimum sum of instance weight (hessian) needed in a child\n",
        "    'gamma': [0.5, 1, 1.5],                     # Minimum loss reduction required to make a further partition on a leaf node\n",
        "    'subsample': [0.7, 0.9],                    # Subsample ratio of the training instances\n",
        "    'colsample_bytree': [0.7, 0.9],             # Subsample ratio of columns when constructing each tree\n",
        "    'n_estimators': [100, 150],                 # Number of trees in the forest\n",
        "    'learning_rate': [0.05, 0.1, 0.15]          # Step size shrinkage used to prevent overfitting\n",
        "}\n",
        "\n",
        "# Initialize the XGBClassifier and RandomizedSearchCV\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "random_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_dist,\n",
        "                                   n_iter=10, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
        "\n",
        "# Fit RandomizedSearchCV to the training data\n",
        "random_search.fit(X_train_bal_8500, y_train_bal_8500)\n",
        "\n",
        "# Extract the best model\n",
        "best_xgb = random_search.best_estimator_\n",
        "\n",
        "# Predict using the best model\n",
        "y_pred_best = best_xgb.predict(X_test_bal_8500)\n",
        "\n",
        "\n",
        "# Evaluate the best model\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "print(\"Accuracy on Test Set:\", accuracy_score(y_test_bal_8500, y_pred_best))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_bal_8500, y_pred_best))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRrYy4_sOFRh",
        "outputId": "a7cf10e4-2fa1-41ff-87ff-eda3c4807076"
      },
      "id": "sRrYy4_sOFRh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "Best Parameters: {'subsample': 0.7, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.15, 'gamma': 0.5, 'colsample_bytree': 0.7}\n",
            "Accuracy on Test Set: 0.8477765108323831\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.74      0.37      0.49      1759\n",
            "         1.0       0.86      0.97      0.91      7011\n",
            "\n",
            "    accuracy                           0.85      8770\n",
            "   macro avg       0.80      0.67      0.70      8770\n",
            "weighted avg       0.84      0.85      0.83      8770\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INITIAL TRAINING FOR LOGISTIC REGRESSION MODEL"
      ],
      "metadata": {
        "id": "NcR8qSJeOy71"
      },
      "id": "NcR8qSJeOy71"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Note: Since we're excluding prediabetes, we'll map '2' (diabetes) to '1' for the binary classification\n",
        "y_binary_no_prediabetes = df_binary['Diabetes_012'].replace({2: 1})\n",
        "\n",
        "# Features remain the same, but filtered to match the rows of the updated target\n",
        "X_binary_no_prediabetes = df_binary.drop('Diabetes_012', axis=1)\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary_no_prediabetes, y_binary_no_prediabetes, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initializing the Logistic Regression classifier\n",
        "lr_classifier = LogisticRegression(random_state=42, max_iter=1000)  # Increased max_iter for convergence\n",
        "\n",
        "# Fitting the model on the training set\n",
        "lr_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting diabetes with the Logistic Regression classifier on the test set\n",
        "y_pred = lr_classifier.predict(X_test)\n",
        "\n",
        "# Evaluating the model's performance\n",
        "print(\"Accuracy on Test Set:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFXzRgXXOzJr",
        "outputId": "ef5aaa51-5a47-49b3-c364-69f7ccac5209"
      },
      "id": "kFXzRgXXOzJr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Test Set: 0.8623368801445492\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.98      0.92     42777\n",
            "         1.0       0.54      0.17      0.26      7033\n",
            "\n",
            "    accuracy                           0.86     49810\n",
            "   macro avg       0.71      0.57      0.59     49810\n",
            "weighted avg       0.83      0.86      0.83     49810\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SECOND TRAINING"
      ],
      "metadata": {
        "id": "Q7H8EaObPW17"
      },
      "id": "Q7H8EaObPW17"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import pandas as pd  # Ensure pandas is imported to handle data operations\n",
        "\n",
        "# Balancing the dataset\n",
        "\n",
        "# Balancing the dataset\n",
        "# Identify the number of instances with diabetes=1\n",
        "n_diabetes_pos = df_binary[df_binary['Diabetes_012'] == 2].shape[0]\n",
        "\n",
        "# Downsample the instances where diabetes=0 to match the number of diabetes=1\n",
        "df_majority = df_binary[df_binary['Diabetes_012'] == 0]\n",
        "df_minority = df_binary[df_binary['Diabetes_012'] == 2]\n",
        "df_majority_downsampled_8500 = resample(df_majority,\n",
        "                                        replace=False,    # sample without replacement\n",
        "                                        n_samples=8500,   # to match minority class count\n",
        "                                        random_state=123) # reproducible results\n",
        "\n",
        "df_balanced_8500 = pd.concat([df_majority_downsampled_8500, df_minority])\n",
        "\n",
        "# Selecting important features\n",
        "important_features = ['HighBP', 'GenHlth', 'HighChol', 'Age_scaled', 'DiffWalk', 'BMI_scaled']\n",
        "X_balanced_8500 = df_balanced_8500[important_features]\n",
        "y_balanced_8500 = df_balanced_8500['Diabetes_012'].replace({2: 1})\n",
        "\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train_bal_8500, X_test_bal_8500, y_train_bal_8500, y_test_bal_8500 = train_test_split(X_balanced_8500, y_balanced_8500, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initializing and training the Logistic Regression classifier\n",
        "lr_classifier_bal_8500 = LogisticRegression(max_iter=1000, random_state=42)  # Increased max_iter for convergence\n",
        "lr_classifier_bal_8500.fit(X_train_bal_8500, y_train_bal_8500)\n",
        "\n",
        "# Making predictions on the test set\n",
        "y_pred_bal_8500 = lr_classifier_bal_8500.predict(X_test_bal_8500)\n",
        "\n",
        "# Generating and printing the classification report and accuracy\n",
        "print(\"Accuracy on Test Set:\", accuracy_score(y_test_bal_8500, y_pred_bal_8500))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_bal_8500, y_pred_bal_8500))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDEJz66UPXFR",
        "outputId": "51b856f8-d895-4741-91d7-3993541348ab"
      },
      "id": "eDEJz66UPXFR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Test Set: 0.8494868871151653\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.76      0.36      0.49      1759\n",
            "         1.0       0.86      0.97      0.91      7011\n",
            "\n",
            "    accuracy                           0.85      8770\n",
            "   macro avg       0.81      0.67      0.70      8770\n",
            "weighted avg       0.84      0.85      0.83      8770\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINAL TRAINING"
      ],
      "metadata": {
        "id": "NkZg_HdTPzTH"
      },
      "id": "NkZg_HdTPzTH"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "n_diabetes_pos = df_binary[df_binary['Diabetes_012'] == 2].shape[0]\n",
        "\n",
        "# Downsample the instances where diabetes=0 to match the number of diabetes=1\n",
        "df_majority = df_binary[df_binary['Diabetes_012'] == 0]\n",
        "df_minority = df_binary[df_binary['Diabetes_012'] == 2]\n",
        "df_majority_downsampled_8500 = resample(df_majority,\n",
        "                                        replace=False,    # sample without replacement\n",
        "                                        n_samples=8500,   # to match minority class count\n",
        "                                        random_state=123) # reproducible results\n",
        "df_balanced_8500 = pd.concat([df_majority_downsampled_8500, df_minority])\n",
        "\n",
        "# Selecting important features\n",
        "important_features = ['HighBP', 'GenHlth', 'HighChol', 'Age_scaled', 'DiffWalk', 'BMI_scaled']\n",
        "X_balanced_8500 = df_balanced_8500[important_features]\n",
        "y_balanced_8500 = df_balanced_8500['Diabetes_012'].replace({2: 1})\n",
        "\n",
        "\n",
        "# Splitting the data\n",
        "X_train_bal_8500, X_test_bal_8500, y_train_bal_8500, y_test_bal_8500 = train_test_split(X_balanced_8500, y_balanced_8500, test_size=0.2, random_state=42)\n",
        "# Parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
        "    'penalty': ['l1', 'l2'],               # Types of regularization\n",
        "    'solver': ['liblinear', 'saga']        # Solvers that support l1 penalties\n",
        "}\n",
        "\n",
        "# GridSearchCV setup\n",
        "grid_search = GridSearchCV(LogisticRegression(max_iter=1000, random_state=42), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
        "grid_search.fit(X_train_bal_8500, y_train_bal_8500)\n",
        "\n",
        "# Best model\n",
        "best_lr = grid_search.best_estimator_\n",
        "\n",
        "# Making predictions and evaluating the best model\n",
        "y_pred_best = best_lr.predict(X_test_bal_8500)\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Accuracy on Test Set:\", accuracy_score(y_test_bal_8500, y_pred_best))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_bal_8500, y_pred_best))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99xloxtgPzDo",
        "outputId": "5dd91c80-84b3-49cb-c15f-2059e07ffe7f"
      },
      "id": "99xloxtgPzDo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "Best Parameters: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Accuracy on Test Set: 0.8494868871151653\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.77      0.36      0.49      1759\n",
            "         1.0       0.86      0.97      0.91      7011\n",
            "\n",
            "    accuracy                           0.85      8770\n",
            "   macro avg       0.81      0.67      0.70      8770\n",
            "weighted avg       0.84      0.85      0.83      8770\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}